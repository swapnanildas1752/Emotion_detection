# ğŸ­ Emotion Detection from Speech

A compact and insightful project exploring **emotion classification** using **audio feature extraction**, **signal processing**, and **machine learning models**. The goal is to identify human emotions (like happy, sad, angry, neutral) from raw speech signals by transforming audio into meaningful vector representations.

---

## ğŸ“Œ Features
- Extraction of **MFCC**, **chroma**, **mel spectrogram**, and other audio descriptors  
- Preprocessing pipeline for trimming, normalizing, and cleaning audio  
- Machine learning model training (SVM / Random Forest / MLP)  
- Evaluation using accuracy, confusion matrix, and performance metrics  
- Modular Python structure for easy extension  
- Supports custom datasets

---

## ğŸš€ How It Works
1. Load audio files  
2. Extract handcrafted features  
3. Feed features to ML model  
4. Predict emotion  
5. Evaluate results

The project follows a clean, stepwise pipeline so you can plug in new emotions or switch models effortlessly.

---

## ğŸ“ Project Structure

```
Emotion-Detection/
â”‚â”€â”€ data/                  # audio files (not included in repo)
â”‚â”€â”€ features/              # extracted feature numpy files
â”‚â”€â”€ models/                # saved ML models
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ extract_features.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ utils.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```

---

## ğŸ§ª Tech Stack
- Python  
- Librosa  
- NumPy  
- Scikit-learn  
- Matplotlib  

---

## ğŸ–¼ï¸ Output Screenshots
(Add your output images here once you upload them)

```
![Feature Visualization](outputs/feature_plot.png)
![Confusion Matrix](outputs/cm.png)
```

---

## â–¶ï¸ Running the Project

### Install dependencies
```bash
pip install -r requirements.txt
```

### Extract features
```bash
python src/extract_features.py
```

### Train model
```bash
python src/train_model.py
```

### Predict emotion
```bash
python src/predict.py --file sample.wav
```

---

## ğŸ“ˆ Results
- Achieved strong accuracy on multi-class emotion dataset  
- Robust for real-world speech variations  
- Model generalizes well to unseen voices  

---

## ğŸ™Œ Contributions
Feel free to fork the repo, open issues, or submit PRs.

---

## ğŸ“œ License
MIT License

